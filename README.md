```markdown
# ğŸš— Proximal Policy Optimization using CARLA Driving Simulator

This repository demonstrates how to run a Reinforcement Learning (RL) experiment with the CARLA Driving Simulator. We implemented the **Proximal Policy Optimization (PPO)** algorithm using **StableBaselines3**.

ğŸ“š **Documentation**: [Stable-Baselines3 Docs](https://stable-baselines3.readthedocs.io/en/master/)

---

## ğŸš€ Instructions

### 1. ğŸ› ï¸ **Create a Conda Environment**

- Follow the official guide to install Miniconda: [Miniconda Installation](https://docs.anaconda.com/miniconda/)
- Create a new Conda environment:
  ```bash
  conda create -n carla python=3.8
  ```
  This requires Python 3.8 for proper compatibility with CARLA.

### 2. âš™ï¸ **Activate Your Conda Environment**

In your command line, run:
```bash
conda activate [env_name]
```

### 3. ğŸ“¦ **Install Dependencies**

Install the necessary Python packages using `pip`:

```bash
pip install stable-baselines3
pip install tensorflow
pip install opencv-python
```

### 4. ğŸ **Run CARLA**

Start the CARLA simulator on your terminal at the specified port number:

```bash
./CarlaUE4.sh -carla-rpc-port=2000 -norelativemousemode
```
(Port 2000 is used in this example)

### 5. ğŸ–¥ï¸ **Open the Files**

- Open `train.py` and `carenv.py` in your favorite IDE.
- Activate the Conda environment in your IDE terminal by running:
  ```bash
  conda activate [env-name]
  ```
  You should see confirmation that the environment is activated.

### 6. ğŸ¬ **Run the Training Script**

Execute the following in your terminal to start training your model:
```bash
python train.py
```

### 7. ğŸ‘€ **Watch Your Model Train!**

Enjoy watching your model improve as it learns from the environment!
```

Make sure that there is no space before or after the `---` for horizontal lines, and this should resolve the issue.
